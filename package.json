{
  "name": "vscode-local-qwen-agent",
  "displayName": "Local Qwen Agent for Chat",
  "description": "Run a local Qwen/Ollama-backed agent inside VS Code Chat with dynamic tool discovery.",
  "version": "0.0.1",
  "publisher": "local",
  "engines": {
    "vscode": "^1.96.0"
  },
  "categories": [
    "AI",
    "Other"
  ],
  "activationEvents": [
    "*",
    "onStartupFinished",
    "onChatParticipant:localQwen.agent"
  ],
  "main": "./dist/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "localQwen.refreshTools",
        "title": "Local Qwen Agent: Refresh Discovered Tools"
      },
      {
        "command": "localQwen.runSmokeTest",
        "title": "Local Qwen Agent: Run Smoke Test"
      },
      {
        "command": "localQwen.listLocalModels",
        "title": "Local Qwen Agent: List Local Models"
      },
      {
        "command": "localQwen.verifyModelProvider",
        "title": "Local Qwen Agent: Verify Model Provider Registration"
      }
    ],
    "chatParticipants": [
      {
        "id": "localQwen.agent",
        "name": "local-qwen",
        "fullName": "Local Qwen Agent",
        "description": "Local Qwen/Ollama agent with dynamic source-based tool discovery.",
        "isSticky": true,
        "commands": [
          {
            "name": "tools",
            "description": "Show discovered tool set"
          }
        ]
      }
    ],
    "languageModelChatProviders": [
      {
        "vendor": "local-ollama",
        "displayName": "Local Ollama"
      }
    ],
    "configuration": {
      "title": "Local Qwen Agent",
      "properties": {
        "localQwen.endpoint": {
          "type": "string",
          "default": "http://localhost:11434",
          "description": "Base URL for local Ollama-compatible API."
        },
        "localQwen.model": {
          "type": "string",
          "default": "qwen2.5:32b",
          "description": "Model name to use for chat requests."
        },
        "localQwen.maxAgentSteps": {
          "type": "number",
          "default": 6,
          "minimum": 1,
          "maximum": 20,
          "description": "Maximum tool-calling turns per request."
        },
        "localQwen.temperature": {
          "type": "number",
          "default": 0.2,
          "minimum": 0,
          "maximum": 2,
          "description": "Sampling temperature for local model requests."
        },
        "localQwen.requestTimeoutMs": {
          "type": "number",
          "default": 120000,
          "minimum": 1000,
          "maximum": 1800000,
          "description": "Maximum time in milliseconds to wait for a single Ollama chat response before aborting."
        },
        "localQwen.modelListTimeoutMs": {
          "type": "number",
          "default": 7000,
          "minimum": 500,
          "maximum": 300000,
          "description": "Maximum time in milliseconds to wait when listing local Ollama models."
        },
        "localQwen.modelListCacheTtlMs": {
          "type": "number",
          "default": 10000,
          "minimum": 1000,
          "maximum": 600000,
          "description": "How long to cache model listing results to avoid repeated endpoint probes."
        },
        "localQwen.maxConcurrentRequests": {
          "type": "number",
          "default": 1,
          "minimum": 1,
          "maximum": 8,
          "description": "Maximum number of concurrent chat requests sent to Ollama by this provider."
        },
        "localQwen.maxOutputTokens": {
          "type": "number",
          "default": 0,
          "minimum": 0,
          "maximum": 8192,
          "description": "Maximum output tokens requested from Ollama per response (mapped to num_predict). Set to 0 to let model defaults decide."
        },
        "localQwen.contextWindowTokens": {
          "type": "number",
          "default": 0,
          "minimum": 0,
          "maximum": 131072,
          "description": "Context window size sent to Ollama (mapped to num_ctx). Set to 0 to use model default context size."
        },
        "localQwen.maxRequestMessages": {
          "type": "number",
          "default": 0,
          "minimum": 0,
          "maximum": 200,
          "description": "Maximum number of recent chat messages forwarded to local model requests. Set to 0 to pass full chat context."
        },
        "localQwen.maxRequestChars": {
          "type": "number",
          "default": 0,
          "minimum": 0,
          "maximum": 1000000,
          "description": "Approximate max character budget for forwarded request history; oldest messages are dropped first. Set to 0 to disable char budgeting."
        },
        "localQwen.maxToolsPerRequest": {
          "type": "number",
          "default": 0,
          "minimum": 0,
          "maximum": 128,
          "description": "Maximum number of tool definitions sent with each chat request. Set to 0 to pass all tools unchanged."
        },
        "localQwen.toolSchemaMode": {
          "type": "string",
          "default": "compact",
          "enum": [
            "compact",
            "full",
            "names-only"
          ],
          "description": "Tool schema payload mode. compact keeps all tool names with minimal schema, full sends full schema/details, names-only sends names with generic object input."
        },
        "localQwen.toolCallBridgeMode": {
          "type": "string",
          "default": "native-then-delimited",
          "enum": [
            "native-then-delimited",
            "native",
            "delimited"
          ],
          "description": "Tool-call transport mode: native uses Ollama tool schema only; delimited injects a tool-call wrapper for non-native models; native-then-delimited retries with wrapper if native tools are unsupported."
        },
        "localQwen.logRequestStats": {
          "type": "boolean",
          "default": true,
          "description": "Log request size diagnostics (approx prompt tokens, message/tool payload size, num_ctx/num_predict) to the Local Qwen output channel."
        },
        "localQwen.toolDiscoveryRoots": {
          "type": "array",
          "default": [],
          "items": {
            "type": "string"
          },
          "description": "Extra absolute paths to scan for tool declarations in source files."
        },
        "localQwen.maxToolSourceFiles": {
          "type": "number",
          "default": 1500,
          "minimum": 100,
          "maximum": 10000,
          "description": "Maximum number of files scanned during tool discovery."
        },
        "localQwen.maxToolSourceBytes": {
          "type": "number",
          "default": 300000,
          "minimum": 50000,
          "maximum": 2000000,
          "description": "Skip files larger than this during tool discovery."
        },
        "localQwen.allowOutsideWorkspaceFileOps": {
          "type": "boolean",
          "default": false,
          "description": "Allow file read/list operations outside the current workspace."
        }
      }
    }
  },
  "scripts": {
    "compile": "tsc -p ./",
    "compile:test": "tsc -p ./tsconfig.test.json",
    "watch": "tsc -watch -p ./",
    "lint": "echo 'No linter configured'",
    "test": "npm run compile:test && node --test dist-test/test/**/*.test.js",
    "copilot:autopatch": "node scripts/copilot-chat-autopatch.mjs",
    "copilot:autopatch:force": "node scripts/copilot-chat-autopatch.mjs --force",
    "copilot:autopatch:watch": "node scripts/copilot-chat-autopatch-watch.mjs"
  },
  "devDependencies": {
    "@types/node": "^20.17.57",
    "@types/vscode": "^1.96.0",
    "typescript": "^5.8.3"
  }
}
